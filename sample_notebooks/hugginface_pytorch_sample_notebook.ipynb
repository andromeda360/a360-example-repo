{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb728d45-66c8-4362-884c-680c0e909762",
   "metadata": {},
   "source": [
    "### A360AI\n",
    "Ensure that the A360AI object is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b3f1ee-7214-43ac-a6fc-af9e22bdb69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a360ai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3321623d-e662-4896-9591-718d0881afe2",
   "metadata": {},
   "source": [
    "This is the project associated with the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b957819f-379f-439d-9cb3-663b06c9f045",
   "metadata": {},
   "outputs": [],
   "source": [
    "a360ai.project_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58886e3-7709-431b-a963-34054cdb5eb6",
   "metadata": {},
   "source": [
    "This is the workspace flavor. It can be any one of 'spark', 'scipy', 'pytorch', 'tensorflow', 'huggingface', or 'xgboost'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dbce31-4cb6-4b66-905c-a7bc15787235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "image_flavor = os.environ[\"A360_IMAGE\"].split(\"-\")\n",
    "if image_flavor[-2] == \"huggingface\":\n",
    "    flavor = \"huggingface\"\n",
    "else:\n",
    "    flavor = image_flavor[-1]\n",
    "flavor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f77c9d-3139-49c2-8e2d-5031837b4365",
   "metadata": {},
   "source": [
    "### Data Repos\n",
    "Data Repos are A360AI objects used to read and write datasets. A project can be associated with multiple datarepos but a datarepo is always associated with a single project.\n",
    "\n",
    "List the datarepos associated with the current project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370931f5-9528-4b17-9c54-cc0cc196eced",
   "metadata": {},
   "outputs": [],
   "source": [
    "datarepos = a360ai.list_datarepos()\n",
    "\n",
    "if datarepos.shape[0] == 0:\n",
    "    raise Exception(f\"No data repos associated with the project {a360ai.project_name}. Please add a datarepo.\")\n",
    "datarepos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bc2deb-24ce-4dc3-818d-a1c35707df1c",
   "metadata": {},
   "source": [
    "#### Select a datarepo\n",
    "Please set the *datarepo_name* variable to a valid string. The ``set_default_datarepo`` method needs to be used in order to access the datasets stored in the specific datarepo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b446ed-c020-44b3-95d3-9f490c18c829",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Can use \"Health Byte - Dev\"\n",
    "\n",
    "datarepo_name = <DATAREPO_NAME> \n",
    "a360ai.set_default_datarepo(datarepo_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4369a6ae-61f1-4269-ac38-053aba5c4209",
   "metadata": {},
   "source": [
    "List the datasets stored in the current datarepo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5b5d93-b59b-4357-ab3f-42e990962af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = a360ai.list_datasets()\n",
    "\n",
    "if datasets.shape[0] == 0:\n",
    "    raise Exception(f\"No datasets associated with the datarepo {datarepo_name}. Please add a dataset.\")\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1825d8d-f32a-481b-9a08-88dca04331c3",
   "metadata": {},
   "source": [
    "#### Select the model type\n",
    "\n",
    "Please specify the type of task to be performed. Options are limited to \"classification\" and \"regression\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9fc02d-63ac-4d12-b525-5d956e22619a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = <MODEL_TYPE> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac58ae2-47ca-4c51-88bd-5e83df03939b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Select the dataset\n",
    "Please set the *dataset_name* variable to a valid string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700571aa-e244-4e24-a382-a85e6b0015d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### For huggingface, \"clickbait_data_200.csv\" (classification) or \n",
    "### \"essay_scoring.csv\" (regression) can be used.\n",
    "\n",
    "dataset_name = <DATASET_NAME> \n",
    "\n",
    "df = a360ai.load_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d8380b-d7c5-43cf-9fff-820ff55c0ef8",
   "metadata": {},
   "source": [
    "#### Specify the target column \n",
    "Please set the target column out of the following columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39d4e52-ec66-43fd-a12b-b51c8d59262f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ba592a-5f9e-4261-8690-acd7a6ddaab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### \"clickbait\" if using \"clickbait_data_200.csv\"\n",
    "### \"score\" if using \"essay_scoring.csv\"\n",
    "\n",
    "target_column = <TARGET_COLUMN> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e464aaf-e773-4ffd-85b7-cc3c2c8bbb9c",
   "metadata": {},
   "source": [
    "#### Please provide the number of classes\n",
    "If the model_type is classification, please specify the number of classes present. An integer should be assigned to the variable ``num_classes``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1ccb7a-5cbd-49a9-a2bf-0b212379ae8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2 if using \"clickbait_data_200.csv\"\n",
    "\n",
    "num_classes = <NUM_CLASSES>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ada30c-fb5e-4471-ba1b-41c58f5fec85",
   "metadata": {},
   "source": [
    "#### Split the dataset into train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbed6a4-1ddc-4981-93fd-08eb98994460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = df.drop(target_column,axis=1), df[target_column]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.1)\n",
    "    \n",
    "num_features = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f7b6fb-6854-4eae-9594-e8fc32288d39",
   "metadata": {},
   "source": [
    "### A360AI Model\n",
    "\n",
    "Create/retrieve an A360AI model. The following arguments need to be passed to the ``get_or_create_model`` method: model_name, version and model_type (default is \"classification\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15650dbc-c92b-4650-9c48-95f79b733e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "unique = str(uuid4())[-6:]\n",
    "\n",
    "model = a360ai.get_or_create_model(\n",
    "    model_name=f\"Sample Notebook {flavor} {model_type} - {unique}\", \n",
    "    version=\"1.0\", \n",
    "    model_type=model_type\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2b9cbc-54d1-4a63-a4a7-8afc7154aac5",
   "metadata": {},
   "source": [
    "### A360AI Experiment\n",
    "\n",
    "Create/retrieve an A360AI experiment. The following arguments need to be passed to the ``get_or_create_experiment`` method of the Model object: experiment_name, model_flavor, train_features and train_target. \n",
    "\n",
    "For huggingface models, the additional parameters need to be provided: pipeline_name, framework and tokenizer. The only framework currently supported for huggingface is \"pt\" (pytorch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0d6fc4-65ae-479d-bc89-2c5248677b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    " \n",
    "train_features = X_train\n",
    "train_target = y_train\n",
    "\n",
    "X_train_df = pd.DataFrame(X_train)\n",
    "y_train_df = pd.DataFrame(y_train)\n",
    "    \n",
    "if model_type == \"classification\":\n",
    "    X_train, y_train = X_train_df, y_train_df\n",
    "    X_test = pd.DataFrame(X_test)\n",
    "    y_test = pd.DataFrame(y_test)\n",
    "        \n",
    "    train_features = X_train_df\n",
    "    train_target = y_train_df\n",
    "    \n",
    "experiment = model.get_or_create_experiment(\n",
    "    experiment_name=f\"sample_notebook_experiment{unique}\",\n",
    "    model_flavor = flavor, \n",
    "    train_features = train_features,\n",
    "    train_target = train_target,\n",
    "    pipeline_name = \"text-classification\",\n",
    "    tokenizer = tokenizer,\n",
    "    framework = \"pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c070c732-60b9-4957-af6e-65a3746e6093",
   "metadata": {},
   "source": [
    "#### View the experiments associated with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac5bdb2-032e-4a39-bb0f-056e20e1404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.list_experiments()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d23f297-2aee-4539-8d7f-a5061629100b",
   "metadata": {},
   "source": [
    "#### Choose the candidate model to be trained.\n",
    "\n",
    "This model will be trained on the train dataset and evaluated on the test dataset. The candidate model will also be logged later after it has been trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1300c437-3b5e-4bab-adef-e29bdd9b2fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import DistilBertForSequenceClassification\n",
    "    \n",
    "class Data(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.x = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __getitem__(self, index):      \n",
    "        item = {key: torch.tensor(val[index]) for key, val in self.x.items()}\n",
    "        item['labels'] = torch.tensor(self.y[index])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "column_name = X_train.columns[0]\n",
    "    \n",
    "if model_type == \"classification\":\n",
    "    X_train = list(X_train[column_name].values)\n",
    "    X_test = list(X_test[column_name].values)\n",
    "else:\n",
    "    X_train = list(X_train[column_name])\n",
    "    X_test = list(X_test[column_name])\n",
    "    \n",
    "if model_type == \"classification\":\n",
    "    y_train = list(y_train.values)\n",
    "    y_test = list(y_test.values)\n",
    "else:\n",
    "    y_train = list(y_train)\n",
    "    y_test = list(y_test)\n",
    "        \n",
    "train_encodings = tokenizer(X_train, truncation=True, padding=True,max_length=512)\n",
    "test_encodings = tokenizer(X_test, truncation=True, padding=True, max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "train_dataset = Data(train_encodings, y_train)\n",
    "test_dataset = Data(test_encodings, y_test)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    \n",
    "if model_type == \"classification\":\n",
    "    num_labels = 2\n",
    "else:\n",
    "    num_labels = 1\n",
    "        \n",
    "candidate_model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=num_labels)\n",
    "\n",
    "candidate_model.to(device)\n",
    "candidate_model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c6a6b6-6af5-440f-8df9-25ff09d8af2e",
   "metadata": {},
   "source": [
    "### Create an A360AI Run\n",
    "\n",
    "Use the Run to log the trained model, metadata, metrics and hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dd4abe-ad1f-457f-8c98-00cc0487703a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "    \n",
    "optimizer = AdamW(candidate_model.parameters(), lr=5e-5)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "train_loss = []\n",
    "        \n",
    "num_epochs = 2\n",
    "    \n",
    "with experiment.run_experiment() as run:\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            train_outputs = candidate_model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = train_outputs[0]\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        train_loss.append(loss)    \n",
    "        print(\"epoch  {}\\t loss : {}\".format(epoch,loss))\n",
    "            \n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        test_outputs = candidate_model(input_ids, attention_mask=attention_mask)\n",
    "        y_pred_outputs = test_outputs.logits.detach().numpy()\n",
    "        \n",
    "    if model_type == \"classification\":\n",
    "        import numpy as np\n",
    "        y_prediction = np.argmax(y_pred_outputs, axis=1)\n",
    "        test_score = accuracy_score(labels, y_prediction)\n",
    "    else:\n",
    "        test_score = mean_squared_error(labels, y_pred_outputs)\n",
    "            \n",
    "    metrics = {\n",
    "        \"test_score\": test_score,  \n",
    "    }\n",
    "        \n",
    "    run.log_metadata({\n",
    "        \"notes\": \"This model was generated with extreme care.\"\n",
    "    })\n",
    "    run.log_metrics(metrics)\n",
    "    run.log_hyperparameters({\n",
    "        \"foo\": 1\n",
    "    })\n",
    "    run.log_model(candidate_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35826cf1-e28e-42f5-99f6-1b9cfa72e20e",
   "metadata": {},
   "source": [
    "#### View the runs associated with the experiment. \n",
    "If the code above has been executed successfully, there will be a new entry in the dataframe returned by the ``list_runs`` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4733ea03-300c-4ecb-88db-e47c38398985",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.list_runs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
